#Piloting Learning - Assessment & Adaptation

By sticking rigidly to a script, whether it's a textbook, a set of notes or a lesson plan, we are essentially planning ourselves into a corner; that process relies on us being able to make reliable assumptions of our learners' knowledge, relies on our learners all having very similar needs so they can be served with the same lesson, and relies on us skillfully constructing what an adequate delivery technique will be. Instead, we want to conduct a more adaptive lesson; one that focuses on identifying & addressing our learners' misconceptions and gaps in knowledge in situ, and gives them multiple distinct opportunities to construct knowledge and understanding accurately and for themselves.

##Summative & Formative Assessment

Any adaptive process requires observations to adapt to - so, we need effective tools to observe & assess student understanding. Student assessment is commonly grouped into two gross categories: *summative*, and *formative*.

**Summative Assessment** is intended to measure learning outcomes; the canonical example is the final exam. A well-designed summative assessment should reveal how well students have met the design goals of a course or lesson, as laid out in the first step of reverse instructional design; its principle use is for deciding if the course as a whole was successful.

**Formative Assessment** is intended to measure student understanding or ability in situ during a course, in order to adapt the course on the fly to optimise the efficacy of that course.

Superficially, these sound pretty similar, up to when exactly they are administered; they both assess student understanding & performance. The key difference between the two is *resolution*; in essence, summative assessment is only required to provide a simple up or down indicator of whether a course did its job or not; but formative assessment has to not only flag gaps in student performance, but resolve *why and how* students are missing the mark, in order to optimally inform instructional course correction.

Institutional western education has converged largely on summative assessment - principally because it's cheaper and easier. Summative assessment can be actualized in standardized testing, which can be administered uniformly at scale, with minimal interruption to already cramped classroom time, and responded to off line in future iterations of a course, as planning time and budget permit. But formative assessment is far more personal, deeper, and operational in real-time; it must be conducted on a per-classroom basis, typically during class time, and appropriate course corrections must be available at the instructor's fingertips. The scale that leads to summative assessment's efficiency is also its greatest weakness; differences between individual classes and cohorts get washed out, and adaptation is slow and can only converge toward a global mean. Formative assessment, though more labor intensive, is also far more nimble.

###Assessment in the Workshop

Time is at a premium in the workshop environment. Taking time out to administer lengthy summative exams or in-depth formative investigations of student performance isn't feasible; we want the adaptivity aspired to by formative assessment, in exercises that take a few minutes.

(see activity assessment_01.html)

##Adaptation
So - you've just administered a quick formative multiple choice question, and the majority of your students are quite convinced that 37+25 = 512; what now? Formative assessment has zeroed in on a misconception; armed with that knowledge, what are some strategies for correcting the problem?

This is one place a densely connected concept map comes in handy. Presumably the first time you taught the misbegotten concept, it was introduced as a node on a concept map connected to some pre-existing scaffolding the students were comfortable with. Perhaps the connection originally explored was more obvious to some students than others; coming at the concept again from a different connection will reinforce the understanding of those that already get it, and give those struggling another run at it. If addition fell flat as a powered-up version of counting, re-examine number representation and the meaning of places and digits, for example.

Repeating nearly identical examples that follow the same lines of reasoning, on the other hand, not only adds little to the conversation, but runs the risk of being counterproductive, by reasserting the confusion that lead to misconception in the first place, thus potentially cementing it even further. The trouble being, that even the most creative instructor eventually runs out of ways to explain the same idea. How can we create a learning environment that's even more adaptive than we are?

###Peer Instruction
No matter how good a teacher you are, you can only pitch a lesson at one level at a time, and phrase your oration one way at a time. In any class (but in open-signup workshops especially), students will come with a very broad distribution of skills and knowledge; the best we can hope to do with lecture alone is to hit the center of that distribution. But what about the tails?

Consider the following recipe, to be followed after a short lesson on a single concept:

 1. Give students an MCQ, probing for misconceptions on the topic just taught.
 2. Have all the students vote publicly on their answers to the MCQ.
 3. Break the class into groups of 3-4, and have them discuss & debate the question within their groups.
 4. Reconvene & explain the correct solution to the MCQ to the class.
 5. Have the students return to their former groups, and discuss the problem again.

The first two steps of this recipe codify the use of a formative question to probe for misunderstandings, but the next three steps each add something more. By getting students to discuss their original answers, they are compelled to clarify their thinking enough to verbalize it, which itself can be enough to call out gaps in reasoning. An opportunity for further explanation after polling the class is then furnished, so the instructor has a chance to diffuse the most common misconception revealed by the public MCQ answers. But perhaps most crucial is the final step; now armed with the correct answer and an explanation of how to arrive at it, students strong enough in the concept can spend a few minutes explaining it to students who need another run at it.

This has numerous benefits. Our original goal was to make our lesson more adaptive than we (or any one individual) could be, and offer multiple different explanations of a concept to maximize students' chances of getting it; by employing the class, we get as many distinct explanations & phrasings of a concept as we have students who get it. Furthermore, those explanations are delivered in a personal and conversational context, so students who need the extra help get essentially personal tutoring in situ. What's more, the experience of teaching gives the stronger students the challenge and opportunity to make their own understanding so clear and well articulated that it can be taught to someone else. By infusing peer instruction into our lessons, we have used those hard-to-reach tails of the skill distribution to help each other.

(see activity assessment_02.html)
